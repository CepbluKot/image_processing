{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "timVyd8L6Rv4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from imutils import paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset GTSRB\n",
              "    Number of datapoints: 26640\n",
              "    Root location: ./data\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=[112, 112], interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize([112, 112]),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "torchvision.datasets.GTSRB(root='./data', split=\"train\", download=True, transform=data_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "learning_rate = 0.001\n",
        "EPOCHS = 15\n",
        "numClasses = 43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples = 21312\n",
            "Number of validation samples = 5328\n"
          ]
        }
      ],
      "source": [
        "train_data_path = \"./data/gtsrb/GTSRB/Training\"\n",
        "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms)\n",
        "\n",
        "ratio = 0.8\n",
        "n_train_examples = int(len(train_data) * ratio)\n",
        "n_val_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, val_data = random_split(train_data, [n_train_examples, n_val_examples])\n",
        "\n",
        "print(f\"Number of training samples = {len(train_data)}\")\n",
        "print(f\"Number of validation samples = {len(val_data)}\")\n",
        "\n",
        "\n",
        "trainloader = DataLoader(train_data, shuffle=True, batch_size = BATCH_SIZE)\n",
        "valloader = DataLoader(val_data, shuffle=True, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            )\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            nn.Linear(12544, output_dim)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate( model, loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in loader:\n",
        "\n",
        "            # Run predictions\n",
        "            output, _ = model(images)\n",
        "            _, predicted = torch.max(output, 1)\n",
        " \n",
        "            y_pred.extend(predicted.numpy())\n",
        "            y_true.extend(labels.numpy())\n",
        "\n",
        "    \n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return accuracy, recall, precision, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to perform training of the model\n",
        "\n",
        "def train(model, loader, opt, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # Train the model\n",
        "    model.train()\n",
        "    \n",
        "    for (images, labels) in loader:\n",
        "\n",
        "        \n",
        "        # Training pass\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        output, _ = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "\n",
        "        # Optimizing weights\n",
        "        opt.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    accuracy, recall, precision, f1 = evaluate(model, loader)\n",
        "\n",
        "    return epoch_loss / len(loader), accuracy, recall, precision, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tSv0GFCDOsky"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 2.187\n",
            "Training - Accuracy: 0.6871715465465466, Recall: 0.6299104447135421, Precision: 0.7906369995571911, F1 Score: 0.652625752399974\n",
            "Validation - Accuracy: 0.6820570570570571, Recall: 0.62505419677975, Precision: 0.7915849368660276, F1 Score: 0.6424018950680908\n",
            "Epoch 2, Loss: 1.013\n",
            "Training - Accuracy: 0.8333333333333334, Recall: 0.809662354905736, Precision: 0.8817895275799338, F1 Score: 0.8326978154831096\n",
            "Validation - Accuracy: 0.81493993993994, Recall: 0.7830919896222606, Precision: 0.8588594831016483, F1 Score: 0.8041306323618749\n",
            "Epoch 3, Loss: 0.711\n",
            "Training - Accuracy: 0.8707301051051051, Recall: 0.855414158172392, Precision: 0.9083721768474102, F1 Score: 0.8692778561780958\n",
            "Validation - Accuracy: 0.8468468468468469, Recall: 0.822368813045981, Precision: 0.8905564626092917, F1 Score: 0.8341833970868942\n",
            "Epoch 4, Loss: 0.587\n",
            "Training - Accuracy: 0.8866366366366366, Recall: 0.8919153118467641, Precision: 0.9115054933836596, F1 Score: 0.8959201022155239\n",
            "Validation - Accuracy: 0.8628003003003003, Recall: 0.8583999933985252, Precision: 0.8886642443562112, F1 Score: 0.8655181554785241\n",
            "Epoch 5, Loss: 0.493\n",
            "Training - Accuracy: 0.9100506756756757, Recall: 0.9066530270952357, Precision: 0.9415858169181821, F1 Score: 0.9208732900227699\n",
            "Validation - Accuracy: 0.8841966966966966, Recall: 0.865498148855806, Precision: 0.9168715701882014, F1 Score: 0.883986468739142\n",
            "Epoch 6, Loss: 0.431\n",
            "Training - Accuracy: 0.9311655405405406, Recall: 0.9315591805715441, Precision: 0.9500264944936123, F1 Score: 0.9388493201643008\n",
            "Validation - Accuracy: 0.9067192192192193, Recall: 0.8930422310273528, Precision: 0.9241252269666906, F1 Score: 0.90393013441805\n",
            "Epoch 7, Loss: 0.392\n",
            "Training - Accuracy: 0.9321509009009009, Recall: 0.9380585927752512, Precision: 0.9452669688604539, F1 Score: 0.9388298893683961\n",
            "Validation - Accuracy: 0.9089714714714715, Recall: 0.9046635313561687, Precision: 0.9152447525066083, F1 Score: 0.9053216274130734\n",
            "Epoch 8, Loss: 0.360\n",
            "Training - Accuracy: 0.940549924924925, Recall: 0.9448894105158606, Precision: 0.9587250085457776, F1 Score: 0.9506655266709004\n",
            "Validation - Accuracy: 0.9194819819819819, Recall: 0.9130482624102837, Precision: 0.9315909424285427, F1 Score: 0.9194121655437624\n",
            "Epoch 9, Loss: 0.341\n",
            "Training - Accuracy: 0.9475412912912913, Recall: 0.9549034565653205, Precision: 0.9668903100328442, F1 Score: 0.9599563355859012\n",
            "Validation - Accuracy: 0.9230480480480481, Recall: 0.9161384138957983, Precision: 0.9422987721372575, F1 Score: 0.9269592999768291\n",
            "Epoch 10, Loss: 0.304\n",
            "Training - Accuracy: 0.9492304804804805, Recall: 0.9568617728416869, Precision: 0.9673584113653337, F1 Score: 0.9611778570647941\n",
            "Validation - Accuracy: 0.9266141141141141, Recall: 0.9184248624045851, Precision: 0.9464155093660246, F1 Score: 0.9298125264640732\n",
            "Epoch 11, Loss: 0.286\n",
            "Training - Accuracy: 0.9588025525525525, Recall: 0.9673814336612678, Precision: 0.9732156151221405, F1 Score: 0.9696861804418221\n",
            "Validation - Accuracy: 0.9376876876876877, Recall: 0.9382430771826004, Precision: 0.9510774083201811, F1 Score: 0.9425116477084067\n",
            "Epoch 12, Loss: 0.282\n",
            "Training - Accuracy: 0.9456174924924925, Recall: 0.9493218002811876, Precision: 0.9673722596451899, F1 Score: 0.9567725475665042\n",
            "Validation - Accuracy: 0.9253003003003003, Recall: 0.9207426760976524, Precision: 0.9476575152620211, F1 Score: 0.9311677503956571\n",
            "Epoch 13, Loss: 0.263\n",
            "Training - Accuracy: 0.9641985735735735, Recall: 0.9704713489068576, Precision: 0.9759079482366422, F1 Score: 0.9725628351945429\n",
            "Validation - Accuracy: 0.941066066066066, Recall: 0.9418488819208599, Precision: 0.9504851201800117, F1 Score: 0.9442914474953811\n",
            "Epoch 14, Loss: 0.253\n",
            "Training - Accuracy: 0.9623216966966966, Recall: 0.97365417778201, Precision: 0.9781356805849541, F1 Score: 0.9754286344321397\n",
            "Validation - Accuracy: 0.9457582582582582, Recall: 0.9456064030691212, Precision: 0.9592551266179187, F1 Score: 0.9511165044594484\n",
            "Epoch 15, Loss: 0.248\n",
            "Training - Accuracy: 0.9641985735735735, Recall: 0.9703643147806897, Precision: 0.9762118375265221, F1 Score: 0.9730073673851876\n",
            "Validation - Accuracy: 0.9412537537537538, Recall: 0.942004268368341, Precision: 0.9478208768059015, F1 Score: 0.9442096829646627\n",
            "Epoch 16, Loss: 0.247\n",
            "Training - Accuracy: 0.9564095345345346, Recall: 0.9681378479147541, Precision: 0.9714039591685047, F1 Score: 0.9691178509738202\n",
            "Validation - Accuracy: 0.931493993993994, Recall: 0.9354955057481904, Precision: 0.939774906720731, F1 Score: 0.9363508201170883\n",
            "Epoch 17, Loss: 0.227\n",
            "Training - Accuracy: 0.9682807807807807, Recall: 0.9759881036080854, Precision: 0.979832687057587, F1 Score: 0.9777019354649612\n",
            "Validation - Accuracy: 0.9461336336336337, Recall: 0.9462661238327056, Precision: 0.9601267091577957, F1 Score: 0.9520144392829161\n",
            "Epoch 18, Loss: 0.220\n",
            "Training - Accuracy: 0.9660754504504504, Recall: 0.9770539747101533, Precision: 0.979359921399446, F1 Score: 0.9779332056185285\n",
            "Validation - Accuracy: 0.9440690690690691, Recall: 0.9446178986339183, Precision: 0.9571424377533174, F1 Score: 0.9500736032658719\n",
            "Epoch 19, Loss: 0.212\n",
            "Training - Accuracy: 0.9673423423423423, Recall: 0.9739940229736734, Precision: 0.9801785081155813, F1 Score: 0.9766680239846123\n",
            "Validation - Accuracy: 0.949512012012012, Recall: 0.9450439016253634, Precision: 0.9629020062393221, F1 Score: 0.9528577276102509\n",
            "Epoch 20, Loss: 0.192\n",
            "Training - Accuracy: 0.9679523273273273, Recall: 0.9715198683435833, Precision: 0.9791658907213521, F1 Score: 0.9748025873961725\n",
            "Validation - Accuracy: 0.9429429429429429, Recall: 0.9336893808553229, Precision: 0.9528921814418155, F1 Score: 0.9413905176582831\n",
            "Epoch 21, Loss: 0.203\n",
            "Training - Accuracy: 0.968140015015015, Recall: 0.976950218335499, Precision: 0.9822138958762202, F1 Score: 0.9791887939098887\n",
            "Validation - Accuracy: 0.9401276276276276, Recall: 0.9445836289982861, Precision: 0.9577402586094543, F1 Score: 0.9500007124078049\n",
            "Epoch 22, Loss: 0.200\n",
            "Training - Accuracy: 0.9779936186186187, Recall: 0.9810022808003892, Precision: 0.9866065005862243, F1 Score: 0.9834162812661794\n",
            "Validation - Accuracy: 0.9538288288288288, Recall: 0.9457287428179596, Precision: 0.9580168711546027, F1 Score: 0.9507454852033195\n",
            "Epoch 23, Loss: 0.184\n",
            "Training - Accuracy: 0.9722691441441441, Recall: 0.9776138988992161, Precision: 0.9797242181582858, F1 Score: 0.9777616360697508\n",
            "Validation - Accuracy: 0.9536411411411412, Recall: 0.9502774880540228, Precision: 0.9560186281862559, F1 Score: 0.9508467528727049\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m accuracy \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.95\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     train_loss, train_accuracy, train_recall, train_precision, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     val_accuracy, val_recall, val_precision, val_f1 \u001b[38;5;241m=\u001b[39m evaluate(net, valloader)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, opt, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (images, labels) \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Training pass\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36mSimpleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     h \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(h)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:791\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "net = SimpleNet(numClasses)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "val_accuracy = 0\n",
        "\n",
        "epoch = 1\n",
        "while val_accuracy < 0.95:\n",
        "    train_loss, train_accuracy, train_recall, train_precision, train_f1 = train(net, trainloader, optimizer, criterion)\n",
        "\n",
        "    val_accuracy, val_recall, val_precision, val_f1 = evaluate(net, valloader)\n",
        "\n",
        "    print(f'Epoch {epoch }, Loss: {train_loss:.3f}')\n",
        "\n",
        "    print(f'Training - Accuracy: {train_accuracy}, Recall: {train_recall}, Precision: {train_precision}, F1 Score: {train_f1}')\n",
        "\n",
        "    print(f'Validation - Accuracy: {val_accuracy}, Recall: {val_recall}, Precision: {val_precision}, F1 Score: {val_f1}')\n",
        "    \n",
        "    epoch += 1\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
